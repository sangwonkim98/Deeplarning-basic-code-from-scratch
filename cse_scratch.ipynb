{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkQdSqtuPLBgpgBLtNxHIz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sangwonkim98/Deeplarning-basic-code-from-scratch/blob/main/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ocf41CXv5b_V"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WrxdyWoP5e5Q"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = [0.8982, 0.805, 0.6393, 0.9983, 0.5731, 0.0469, 0.556, 0.1476, 0.8404, 0.5544]\n",
        "target = [1]\n",
        "loss = np.log(sum(np.exp(output))) - output[target[0]]\n",
        "print(loss) # 2.143818427948945\n",
        "\n",
        "## 첫번쨰 방법 수학수식 이용 그대로 쓴다.\n"
      ],
      "metadata": {
        "id": "eur0ttg1rOAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x= torch.Tensor([[0.8982, 0.805, 0.6393, 0.9983,0.5731,0.0469,0.556,0.1476,0.8404,0.5544]])\n",
        "y = torch.LongTensor([1])\n",
        "#case = 1\n",
        "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "print(cross_entropy_loss(x,y))\n",
        "\n",
        "## torch.nn.CrossEntropyLoss 펑션그냥 쓰기 x,y (데이터, 타겟값넣는다. 차원수는 안맞춰도되나?)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2UI8ASa7Nnq",
        "outputId": "cb324b14-a3de-48e2-ddf5-15f05374783b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.1438)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#case =2\n",
        "def NLLLoss(logs, targets):\n",
        "  out = torch.zeros_like(targets, dtype = torch.float)\n",
        "## 타겟크기를 갖는 여기서는 타겟 이 [1] 뭐이렇게들어오면 1X1이겠지 -> [0]으로 초기화 해놓는다 자료형은 부동소수점 Float\n",
        "  for i in range(len(targets)):\n",
        "    out[i] = logs[i][targets[i]]\n",
        "  return -out.sum()/len(out)\n",
        "## target의개수 -> 즉 배치안에들어가는 샘플데이터세트 개수만큼\n",
        "## out[i]에 logs로들어온것의 타겟 인덱스만꺼낸다 (ce이니까 )\n",
        "## 샘플데이터개수로 평균화한다.\n",
        "\n",
        "log_softmax = torch.nn.LogSoftmax(dim =1)\n",
        "x_log = log_softmax(x)\n",
        "print(x_log)\n",
        "## X_log까지하면 Log(softmax된 상태)\n",
        "print(NLLLoss(x_log, y)) #\n",
        "\n",
        "\n",
        "##두번쨰방법 torch.nn.LogSoftmax 적용후 , 미리 구해놓은 NLLLoss (log,y) 넣는방식."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwq2_-6F7-dN",
        "outputId": "7fd95168-eb0d-46df-9449-8a53d929e521"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2.0506, -2.1438, -2.3095, -1.9505, -2.3757, -2.9019, -2.3928, -2.8012,\n",
            "         -2.1084, -2.3944]])\n",
            "tensor(2.1438)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "muR3eihV8L8X"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 또라이맞는듯 이거손으로 이렇게해놨네\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "output = torch.Tensor(\n",
        "    [\n",
        "        [0.8982, 0.805, 0.6393, 0.9983, 0.5731, 0.0469, 0.556, 0.1476, 0.8404, 0.5544],\n",
        "        [0.9457, 0.0195, 0.9846, 0.3231, 0.1605, 0.3143, 0.9508, 0.2762, 0.7276, 0.4332]\n",
        "    ]\n",
        ")\n",
        "target = torch.LongTensor([1, 5])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = criterion(output, target)\n",
        "print(loss) # tensor(2.3519)\n",
        "\n",
        "# 걍 이것만 얻어가자. nn.CrossEntropyLoss 써서 결국에 loss 를 아웃풋, 타겟을넣어서\n",
        "## 타겟에 적혀있는 아웃풋에서 꺼내와야할 목록을 꺼내서 로그소프트 -> Ce 계산한다. 레이블 다수일떈\n",
        "## 다더해서 나눈다 ㅋㅋ ㅗㅗㅗ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wur0NSpz8UqU",
        "outputId": "e3c4b49f-01cf-4a22-9074-304e7486fd46"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3519)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = [0.8982, 0.805, 0.6393, 0.9983, 0.5731, 0.0469, 0.556, 0.1476, 0.8404, 0.5544]\n",
        "target = [1]\n",
        "loss1 = np.log(sum(np.exp(output))) - output[target[0]]\n",
        "output = [0.9457, 0.0195, 0.9846, 0.3231, 0.1605, 0.3143, 0.9508, 0.2762, 0.7276, 0.4332]\n",
        "target = [5]\n",
        "loss2 = np.log(sum(np.exp(output))) - output[target[0]]\n",
        "print((loss1 + loss2)/2) # 2.351937720511233\n"
      ],
      "metadata": {
        "id": "W-CcPkr38nlC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
